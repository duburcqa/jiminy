<div align="center">
  <a href="#"><img width="400px" height="auto" src="https://raw.github.com/duburcqa/jiminy/readme/jiminy_logo.svg"></a>
</div>

____

[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Version](https://img.shields.io/pypi/v/jiminy-py)](https://pypi.org/project/jiminy-py)
[![Python](https://img.shields.io/pypi/pyversions/jiminy-py.svg)](https://www.python.org/downloads/)
[![Downloads](https://static.pepy.tech/personalized-badge/jiminy-py?period=month&units=international_system&left_color=blue&right_color=orange)](https://pepy.tech/project/jiminy-py)
[![Try it in Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/duburcqa/jiminy.git/demo?labpath=tutorial.ipynb)
[![Try it in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/duburcqa/jiminy/blob/demo/tutorial.ipynb)
[![Try in in Deepnote](https://img.shields.io/badge/Try%20it-Deepnote-blue?logo=data:image/png;base64,AAABAAEAEBAAAAEAIABoBAAAFgAAACgAAAAQAAAAIAAAAAEAIAAAAAAAQAQAAAAAAAAAAAAAAAAAAAAAAADCbwOXtGUC/7RlAv+0ZQL/tGUC/7RlAv+zZAL8p1kN5c2ALr72oD98+LRXKf///wIAAAAAAAAAAAAAAAAAAAAA7KMSDrprAs+0ZQL/tGUC/7RlAv+0ZQL/tGUC/7JkAv+FPwL/w3Al//KWN/n0nj2m97hVJAAAAAAAAAAAAAAAAAAAAADQfAUxuWkC87RlAv+0ZQL/tGUC/7RlAv+0ZQL/qVwB/3MxBP/lizP/75M3//SXOun7pURHAAAAAAAAAAAAAAAAAAAAAMVzAmq1ZgL9tGUC/7RlAv+0ZQL/tGUC/7NkAv9tLAD/xXIm/++TN//vkzf/8pY48fSoQjIAAAAAAAAAAAAAAAD/v38EwG4Eq7RlAv+0ZQL/tGUC/7RlAv+lWQH/aCgA/7tqIv/vkzf/75M3/++TN//zmDzD//+/BAAAAAAAAAAAAAAAAN+fFRi6aQLetGUC/7JjAv+eUwH/ci8A/2goAP/OeSn/75M3/++TN//vkzf/8pU3/fKxSTsAAAAAAAAAAAAAAAAAAAAAtWAHQoA6APlxLwD/aCgA/2goAP+HQA3/7JA1/++TN//vkzf/75M3/++TN//4oDx/AAAAAAAAAAAAAAAAAAAAAP//AAF2LwCMaCgA/20sA/+ZTxT/5Ysz/++TN//vkzf/75M3/++TN//vkzf/8Z8+qPapRHvwnkCe8J5AnvCeQJ7wnkCe6pY5rc95KfzkijL/75M3/++TN//vkzf/75M3/++TN//vkzf/75M3//ajQ7L6rkw/8pc4+e+TN//vkzf/75M3/++TN//vkzf/75M3/++TN//vkzf/75M3/++TN//vkzf/75M3/++TN//ynUCf////AfWgPYnvkzf/75M3/++TN//vkzf/75M3/++TN//vkzf/75M3/++TN//vkzf/75M3/++TN//vkzf/96VCbAAAAAD/v1UM8Zk6zu+TN//vkzf/75M3/++TN//vkzf/75M3/++TN//vkzf/75M3/++TN//vkzf/8pc58vbBTx0AAAAAAAAAAPWoQzXxljj175M3/++TN//vkzf/75M3/++TN//vkzf/75M3/++TN//vkzf/8ZQ3/vSkPncAAAAAAAAAAAAAAAAAAAAA858/gPGUN/7vkzf/75M3/++TN//vkzf/75M3/++TN//vkzf/8pU5+/SgP4z//6oDAAAAAAAAAAAAAAAAAAAAAP/MZgrymjrK75M3/++TN//vkzf/75M3//CTN//ylDj78Zo6yvisSEr///8BAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9ahDNfCVOfbwlTjz8pY43PKdPbH0oD5/9q5MOf//qgMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==&style=flat)](https://deepnote.com/workspace/alexis-duburcq-7e87783d-6f49-4586-ae21-9967ef0c7882/project/jiminy-demo-3999591e-5f92-4474-96cc-cddc08b5d295/%2Ftutorial.ipynb)
[![Linux CI](https://github.com/duburcqa/jiminy/actions/workflows/linux.yml/badge.svg?branch=master)](https://github.com/duburcqa/jiminy/actions/workflows/linux.yml)
[![MacOS CI](https://github.com/duburcqa/jiminy/actions/workflows/macos.yml/badge.svg?branch=master)](https://github.com/duburcqa/jiminy/actions/workflows/macos.yml)
[![Windows CI](https://github.com/duburcqa/jiminy/actions/workflows/win.yml/badge.svg?branch=master)](https://github.com/duburcqa/jiminy/actions/workflows/win.yml)

Jiminy is a cross-platform open-source simulator for poly-articulated systems. It was built with two ideas in mind:

- **provide a fast yet physically accurate simulator for robotics research.**

Jiminy is built around [Pinocchio](https://github.com/stack-of-tasks/pinocchio), an open-source fast and efficient kinematics and dynamics library. Jiminy thus uses minimal coordinates and Lagrangian dynamics to simulate an articulated system: this makes Jiminy as close as numerically possible to an analytical solution, without the risk of joint violation.

- **build an efficient and flexible platform for machine learning in robotics.**

Beside a strong focus on performance to answer machine learning's need for running computationally demanding distributed simulations, Jiminy offers convenience tools for learning via a dedicated module [Gym-Jiminy](#gym-jiminy). It is fully compliant with `gym` standard API and provides a highly customizable wrapper to interface any robotics system with state-of-the-art learning frameworks.

## Key features

### General

- Simulation of multi-body systems using minimal coordinates and Lagrangian dynamics.
- Comprehensive API for computing dynamic quantities and their derivatives thanks to Pinocchio.
- C++ core with full python bindings, providing user API parity between both languages.
- Designed with machine learning in mind, with seamless wrapping of robots as [OpenAI Gym](https://github.com/openai/gym) environments using one-liners. Jiminy provides both the physical engine and the robot model (including sensors) required for learning.
- Rich simulation log output, easily customizable for recording, introspection and debugging. The simulation log is made available in RAM directly for fast access, and can be exported in raw binary or [HDF5](./docs/spec/src/tlmc_format_specification.md) format.
- Dedicated integration in Google Colab, Jupyter Lab, Mybinder and VSCode working out-of-the-box - including interactive 3D viewer based on [Meshcat](https://github.com/rdeits/MeshCat.jl). This facilitates working on remote environments.
- Synchronous and single-threaded offscreen rendering capability, GPU-accelerated without graphical server, based on [Panda3d](https://github.com/panda3d/panda3d).
- Easy to install: `pip` is all that is needed to [get you started](#getting-started) ! Support Linux, Mac and Windows platforms.

### Physics

- Provide both classical phenomenological force-level spring-damper contact model and constraint solver satisfying the maximum energy dissipation principle.
- Support contact and collision with the ground from a fixed set of contact points (primitives and meshes yet to come).
- Simulate multiple articulated systems simultaneously interacting with each other, to support use cases such as multi-agent learning or swarm robotics.
- Compliant spherical joints with spring-damper dynamics to model mechanical deformation, a common phenomenon particularly in legged robotics.
- Simulate both continuous or discrete-time controller, with possibly different controller and sensor update frequencies.

A more complete list of features is available on the [wiki](https://github.com/duburcqa/jiminy/wiki).

**The documentation is available on [Github.io](https://duburcqa.github.io/jiminy/), or locally in `docs/html/index.html` if built from source.**

## Gym Jiminy

Gym Jiminy is an interface between Jiminy simulator and reinforcement learning frameworks. It is fully compliant with now standard [Open AI Gym](https://github.com/openai/gym) API. Additionally, it offers a generic and easily configurable learning environment for learning locomotion tasks, with minimal intervention from the user, who usually only needs to provide the robot's [URDF](https://wiki.ros.org/urdf) file. Furthermore, Gym Jiminy enables easy modification of many aspects of the simulation to provide richer exploration and ensure robust learning. This ranges from external perturbation forces to sensor noise and bias, including randomization of masses and inertias, ground friction model or even gravity itself. Note that learning can
easily be done on any high-level dynamics features, or restricted to mock sensor data for end-to-end learning.

Gym is cross-platform and compatible with most Reinforcement Learning frameworks implementing standard algorithms. For instance, [Stable Baselines 3](https://github.com/DLR-RM/stable-baselines3), [Tianshou](https://github.com/thu-ml/tianshou), or [Rllib](https://github.com/ray-project/ray). Stable Baselines 3 and Tianshou use its counterpart [Pytorch](https://pytorch.org/), and Rllib supports both. A few learning examples relying on those packages are also provided.

Pre-configured environments for some well-known toys models and reference robotics platforms are provided: [cartpole](https://gym.openai.com/envs/CartPole-v1/), [acrobot](https://gym.openai.com/envs/Acrobot-v1/), [pendulum](https://gym.openai.com/envs/Pendulum-v0/), [Ant](https://gym.openai.com/envs/Ant-v2/), [ANYmal](https://www.anymal-research.org/#getting-started), and [Cassie](https://www.agilityrobotics.com/robots#cassie), and [Atlas](https://www.bostondynamics.com/atlas).

## Demo

<a href="./python/jiminy_py/examples/tutorial.ipynb">
<p align="middle">
  <img src="https://raw.github.com/duburcqa/jiminy/readme/jiminy_plot_log.png" width="49.0%"/>
  <img src="https://raw.github.com/duburcqa/jiminy/readme/jiminy_viewer_open.png" width="49.0%"/>
  <img src="https://raw.github.com/duburcqa/jiminy/readme/jiminy_tensorboard_cartpole.png" width="98.5%"/>
  <img src="https://raw.github.com/duburcqa/jiminy/readme/jiminy_learning_ant.gif" width="32.5%"/>
  <img src="https://raw.github.com/duburcqa/jiminy/readme/cassie.png" width="32.5%"/>
  <img src="https://raw.github.com/duburcqa/jiminy/readme/atlas.png" width="32.5%"/>
</p>
</a>

## Getting started

Jiminy and Gym Jiminy support Linux, Mac and Windows, and is compatible with Python3.8+. Pre-compiled binaries are distributed on PyPi. They can be installed using `pip>=20.3`:

```bash
# For installing Jiminy
python -m pip install --prefer-binary jiminy_py[meshcat,plot]

# For installing Gym Jiminy
python -m pip install --prefer-binary gym_jiminy[all]
```

Detailed installation instructions, including building from source, are available [here](./INSTALL.md).
